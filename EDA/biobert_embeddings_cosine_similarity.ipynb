{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67226c9a-c830-4969-bb1e-9630cf9c90f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install featexp\n",
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a840688-3a32-4cbe-93b2-e4f21d99c4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from pyspark.sql.functions import datediff, col\n",
    "from pyspark.sql.functions import col, explode_outer, lpad, regexp_replace\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import posexplode, concat, lit\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a12f83e-a100-4da1-801a-f0b695ad1082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\n|            claim_id|          patient_id|admission_dt|discharge_dt|diag_cd|patient_gender|patient_year_of_birth|          paid_amt|\n+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\n|fad89d0b186063f39...|46efcda6fafac85bf...|  2019-07-11|  2019-07-14|   R531|             M|                 1944|141109.66128074378|\n|f73e9acb6759baf70...|0a3e83e5fc70ce368...|  2023-09-03|  2023-09-09|  F1120|             M|                 1986| 876162.4331475049|\n+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\nonly showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "# read into a dataframe\n",
    "raw=spark.sql(\"\"\" select diagnosis.claim_id,diagnosis.patient_id,diagnosis.date_service,diagnosis.date_service_end,diagnosis_code,enrollment.patient_gender,patient_year_of_birth,sum(procedure.line_charge) as paid_amt \n",
    "from healthverity_claims_sample_patient_dataset.hv_claims_sample.diagnosis \n",
    "inner join healthverity_claims_sample_patient_dataset.hv_claims_sample.enrollment on diagnosis.patient_id = enrollment.patient_id\n",
    "inner join healthverity_claims_sample_patient_dataset.hv_claims_sample.procedure on diagnosis.patient_id = procedure.patient_id\n",
    "where admit_diagnosis_ind='Y'\n",
    "group by all\"\"\")\n",
    "raw = raw.withColumnRenamed(\"date_service\", \"admission_dt\").withColumnRenamed(\"date_service_end\", \"discharge_dt\").withColumnRenamed(\"diagnosis_code\",\"diag_cd\")\n",
    "raw.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15c9501-7ad3-466b-a5cb-c3551c7a212c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load BioBERT (pretrained)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b591de83-75d3-4b40-b19c-5f4c5b59bd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of diagnosis codes with the description\n",
    "code_desc = {\n",
    "    \"S066X0D\": \"Traumatic brain injury, unspecified, subsequent encounter\",\n",
    "    \"F1120\": \"Opioid dependence, uncomplicated\",\n",
    "    \"Z3483\": \"Encounter for supervision of high-risk pregnancy\",\n",
    "    \"K440\": \"Umbilical hernia without obstruction or gangrene\",\n",
    "    \"M75102\": \"Bursitis of right shoulder\",\n",
    "    \"I69354\": \"Hemiplegia and hemiparesis following cerebral infarction affecting left non-dominant side\",\n",
    "    \"L97929\": \"Non-pressure chronic ulcer of unspecified part of left lower leg with unspecified severity\",\n",
    "    \"R531\": \"Weakness\",\n",
    "    \"K5720\": \"Diverticulosis of intestine, part unspecified, without perforation or abscess\",\n",
    "    \"I214\": \"Acute subendocardial myocardial infarction\",\n",
    "    \"K9189\": \"Other postprocedural complications and disorders of digestive system\",\n",
    "    \"I495\": \"Sick sinus syndrome\",\n",
    "    \"S82122D\": \"Displaced transverse fracture of shaft of left tibia, subsequent encounter\",\n",
    "    \"T85730A\": \"Infection and inflammatory reaction due to other cardiac and vascular devices, implants and grafts, initial encounter\",\n",
    "    \"M238X2\": \"Other instability, left lower leg\",\n",
    "    \"R45851\": \"Suicidal ideation\",\n",
    "    \"G9341\": \"Acute encephalopathy\",\n",
    "    \"K8510\": \"Acute pancreatitis without necrosis or infection\",\n",
    "    \"R509\": \"Fever, unspecified\",\n",
    "    \"Z432\": \"Encounter for attention to gastrostomy\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9aedc22-2912-4f80-b353-c87c693126b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    print(emb.shape)\n",
    "    return emb\n",
    "\n",
    "# Precompute: Get embedding for every code\n",
    "dx_embeddings = {code: get_embedding(desc) for code, desc in code_desc.items()}\n",
    "\n",
    "embedding_size = list(dx_embeddings.values())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b070605-28cb-435a-acbd-4ce89456d671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 8)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>admission_dt</th>\n",
       "      <th>discharge_dt</th>\n",
       "      <th>diag_cd</th>\n",
       "      <th>patient_gender</th>\n",
       "      <th>patient_year_of_birth</th>\n",
       "      <th>paid_amt</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>dx_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fad89d0b186063f393bb82e8cc50c1fb</td>\n",
       "      <td>46efcda6fafac85bfc9735969d26afc8</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>2019-07-14</td>\n",
       "      <td>R531</td>\n",
       "      <td>M</td>\n",
       "      <td>1944</td>\n",
       "      <td>141109.661281</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.36756817, -0.1471743, -0.26920772, 0.170978...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f73e9acb6759baf704968975b9e92c64</td>\n",
       "      <td>0a3e83e5fc70ce368803d9f3c16a42ce</td>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>F1120</td>\n",
       "      <td>M</td>\n",
       "      <td>1986</td>\n",
       "      <td>876162.433148</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.035627544, -0.035316434, 0.03306435, -0.284...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           claim_id                        patient_id  \\\n",
       "0  fad89d0b186063f393bb82e8cc50c1fb  46efcda6fafac85bfc9735969d26afc8   \n",
       "1  f73e9acb6759baf704968975b9e92c64  0a3e83e5fc70ce368803d9f3c16a42ce   \n",
       "\n",
       "  admission_dt discharge_dt diag_cd patient_gender patient_year_of_birth  \\\n",
       "0   2019-07-11   2019-07-14    R531              M                  1944   \n",
       "1   2023-09-03   2023-09-09   F1120              M                  1986   \n",
       "\n",
       "        paid_amt  length_of_stay  \\\n",
       "0  141109.661281               3   \n",
       "1  876162.433148               6   \n",
       "\n",
       "                                              dx_vec  \n",
       "0  [0.36756817, -0.1471743, -0.26920772, 0.170978...  \n",
       "1  [0.035627544, -0.035316434, 0.03306435, -0.284...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert diagnosis codes to vectors/embeddings\n",
    "def codes_to_vec(codes_str):\n",
    "    codes = codes_str.split('|')\n",
    "    vecs = [dx_embeddings[c] for c in codes if c in dx_embeddings]\n",
    "    if vecs:\n",
    "        return np.mean(vecs, axis=0)\n",
    "    else:  # Fallback: zero vector\n",
    "        return np.zeros(embedding_size)\n",
    "\n",
    "# Apply to your claims dataframe\n",
    "df =raw.toPandas()\n",
    "print(df.shape)\n",
    "df['admission_dt'] = pd.to_datetime(df['admission_dt'])\n",
    "df['discharge_dt'] = pd.to_datetime(df['discharge_dt']) \n",
    "\n",
    "# Feature engineering: calculate length of stay\n",
    "df['length_of_stay'] = (df['discharge_dt'] - df['admission_dt']).dt.days.astype('int') \n",
    "\n",
    "df['dx_vec'] = df['diag_cd'].apply(codes_to_vec)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f913dd0f-a785-4897-8459-f575addf199a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First diagnosis:  R531\nSecond diagnosis:  R45851\nCosine similarity: 0.8664155\n"
     ]
    }
   ],
   "source": [
    "vec1 = df.iloc[0]['dx_vec']\n",
    "vec2 = df.iloc[30]['dx_vec']\n",
    "\n",
    "print(\"First diagnosis code: \",df.iloc[0]['diag_cd'])\n",
    "print(\"Second diagnosis code: \",df.iloc[30]['diag_cd'])\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "print('Cosine similarity:', cos_sim)\n",
    "# A cosine similarity value of 0.99 means that the two vectors (data points, text embeddings, or documents) are extremely similar and point in almost the exact same direction. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "biobert_embeddings_cosine_similarity",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
