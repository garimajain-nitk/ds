{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b738b2eb-3476-41d3-a9e1-607752f051ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load a sample dataset (e.g., Iris)\n",
    "data = load_iris()\n",
    "X = data.data      # shape (150, 4)\n",
    "y = data.target    # labels for plotting\n",
    "\n",
    "# Standardize the data (important for PCA in real cases)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Apply PCA: reduce to 2 principal components for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "print(\"Explained variance ratios:\", pca.explained_variance_ratio_)\n",
    "print(\"Principal components:\\n\", pca.components_)\n",
    "cov_matrix = pca.get_covariance()\n",
    "print(cov_matrix)\n",
    "\n",
    "# Plot the transformed data in the space of principal components\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in np.unique(y):\n",
    "    plt.scatter(X_pca[y == label, 0], X_pca[y == label, 1], label=data.target_names[label])\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA of Iris Dataset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662fe640-06b5-4ebb-9cbf-9c3ab01456c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step1: Compute covariance matrix\n",
    "# Note: Each column is a feature variable\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "cov_matrix = np.cov(X_std, rowvar=False)\n",
    "\n",
    "print(\"Covariance matrix:\\n\", cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e6c5bda-3c9e-45da-adb4-5f87a1485b76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Compute eigenvalues and eigenvectors\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "print(\"\\nEigenvalues:\\n\", eig_vals)\n",
    "print(\"\\nEigenvectors:\\n\", eig_vecs)\n",
    "\n",
    "[[ 0.52106591 -0.26934744  0.5804131   0.56485654]\n",
    " [ 0.37741762  0.92329566  0.02449161  0.06694199]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1decf83-2eca-4f58-9aa7-662732bd43a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Sort the eigenvalues and eigenvectors from largest to smallest eigenvalue\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]  # indices for sorting in descending order\n",
    "sorted_eig_vals = eig_vals[sorted_indices]\n",
    "sorted_eig_vecs = eig_vecs[:, sorted_indices]\n",
    "\n",
    "print(\"Sorted Eigenvalues:\\n\", sorted_eig_vals)\n",
    "print(\"\\nSorted Eigenvectors:\\n\", sorted_eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee0b518-d4db-431c-ac9b-75392612146e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Keep the two largest eigenvalues and their associated eigenvectors\n",
    "top_k = 2\n",
    "top_eig_vals = sorted_eig_vals[:top_k]\n",
    "top_eig_vecs = sorted_eig_vecs[:, :top_k]\n",
    "\n",
    "print(\"Top 2 Eigenvalues:\\n\", top_eig_vals)\n",
    "print(\"\\nAssociated Eigenvectors:\\n\", top_eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a7e4c8a-4a13-42b5-978f-9c56a614be2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Create a matrix where each column is a top eigenvector scaled by its norm\n",
    "normalized_eig_vecs = np.zeros_like(top_eig_vecs)\n",
    "for i in range(top_eig_vecs.shape[1]):\n",
    "    norm = np.linalg.norm(top_eig_vecs[:, i])\n",
    "    normalized_eig_vecs[:, i] = top_eig_vecs[:, i] / norm\n",
    "\n",
    "print(\"Matrix with normalized eigenvectors (each column scaled by its norm):\\n\", normalized_eig_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a46f3c4-babd-4a59-8138-b6d9b3f314cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Project the original data onto the normalized top 2 eigenvectors to get the final 2D dataset\n",
    "projected_data = X_std @ normalized_eig_vecs\n",
    "\n",
    "# print(\"Data projected onto top 2 normalized eigenvectors:\\n\", projected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6f3c49-1814-4535-ab61-0951e51d6f2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot the transformed data in the space of principal components\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in np.unique(y):\n",
    "    plt.scatter(projected_data[y == label, 0], projected_data[y == label, 1], label=data.target_names[label])\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA of Iris Dataset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sklearnPCA_vs_explicit_calculation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
