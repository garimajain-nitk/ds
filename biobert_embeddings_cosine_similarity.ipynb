{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67226c9a-c830-4969-bb1e-9630cf9c90f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting featexp\n  Downloading featexp-0.0.7-py3-none-any.whl.metadata (675 bytes)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (from featexp) (2.2.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.12/site-packages (from featexp) (2.1.3)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.12/site-packages (from featexp) (3.10.0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (24.1)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib->featexp) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas->featexp) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas->featexp) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->featexp) (1.16.0)\nDownloading featexp-0.0.7-py3-none-any.whl (6.2 kB)\nInstalling collected packages: featexp\nSuccessfully installed featexp-0.0.7\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting transformers\n  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\nCollecting torch\n  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (31 kB)\nCollecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.12/site-packages (from transformers) (2.1.3)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.12/site-packages (from transformers) (6.0.2)\nCollecting regex!=2019.12.17 (from transformers)\n  Downloading regex-2026.1.15-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (40 kB)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.3 kB)\nCollecting typer-slim (from transformers)\n  Downloading typer_slim-0.23.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting safetensors>=0.4.3 (from transformers)\n  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.1 kB)\nCollecting tqdm>=4.27 (from transformers)\n  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (4.12.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\nCollecting sympy>=1.13.3 (from torch)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting networkx>=2.5.1 (from torch)\n  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.1.5)\nRequirement already satisfied: fsspec>=0.8.5 in /databricks/python3/lib/python3.12/site-packages (from torch) (2023.5.0)\nCollecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_28_aarch64.whl.metadata (4.9 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /databricks/python3/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.27.0)\nCollecting shellingham (from huggingface-hub<2.0,>=1.3.0->transformers)\n  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\nCollecting typer>=0.23.0 (from typer-slim->transformers)\n  Downloading typer-0.23.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.6.2)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.2)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.14.0)\nRequirement already satisfied: click>=8.0.0 in /databricks/python3/lib/python3.12/site-packages (from typer>=0.23.0->typer-slim->transformers) (8.1.7)\nRequirement already satisfied: rich>=10.11.0 in /databricks/python3/lib/python3.12/site-packages (from typer>=0.23.0->typer-slim->transformers) (13.9.4)\nCollecting annotated-doc>=0.0.2 (from typer>=0.23.0->typer-slim->transformers)\n  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->transformers) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->transformers) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /databricks/python3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.0->typer-slim->transformers) (0.1.0)\nDownloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/10.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.3/10.3 MB\u001B[0m \u001B[31m121.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading torch-2.10.0-cp312-cp312-manylinux_2_28_aarch64.whl (146.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/146.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.8/146.0 MB\u001B[0m \u001B[31m304.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m \u001B[32m115.3/146.0 MB\u001B[0m \u001B[31m287.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m145.8/146.0 MB\u001B[0m \u001B[31m275.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.0/146.0 MB\u001B[0m \u001B[31m191.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/553.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m553.3/553.3 kB\u001B[0m \u001B[31m21.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m63.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading regex-2026.1.15-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (798 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/798.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m798.7/798.7 kB\u001B[0m \u001B[31m32.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (491 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/6.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m139.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m114.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.3-py3-none-any.whl (78 kB)\nDownloading typer_slim-0.23.0-py3-none-any.whl (3.4 kB)\nDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_28_aarch64.whl (3.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m99.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/536.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading typer-0.23.0-py3-none-any.whl (56 kB)\nDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\nDownloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\nInstalling collected packages: mpmath, tqdm, sympy, shellingham, safetensors, regex, networkx, hf-xet, annotated-doc, torch, typer, typer-slim, huggingface-hub, tokenizers, transformers\nSuccessfully installed annotated-doc-0.0.4 hf-xet-1.2.0 huggingface-hub-1.4.1 mpmath-1.3.0 networkx-3.6.1 regex-2026.1.15 safetensors-0.7.0 shellingham-1.5.4 sympy-1.14.0 tokenizers-0.22.2 torch-2.10.0 tqdm-4.67.3 transformers-5.1.0 typer-0.23.0 typer-slim-0.23.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install featexp\n",
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a840688-3a32-4cbe-93b2-e4f21d99c4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from pyspark.sql.functions import datediff, col\n",
    "from pyspark.sql.functions import col, explode_outer, lpad, regexp_replace\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import posexplode, concat, lit\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a12f83e-a100-4da1-801a-f0b695ad1082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\n|            claim_id|          patient_id|admission_dt|discharge_dt|diag_cd|patient_gender|patient_year_of_birth|          paid_amt|\n+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\n|fad89d0b186063f39...|46efcda6fafac85bf...|  2019-07-11|  2019-07-14|   R531|             M|                 1944|141109.66128074378|\n|f73e9acb6759baf70...|0a3e83e5fc70ce368...|  2023-09-03|  2023-09-09|  F1120|             M|                 1986| 876162.4331475049|\n+--------------------+--------------------+------------+------------+-------+--------------+---------------------+------------------+\nonly showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "# read into a dataframe\n",
    "raw=spark.sql(\"\"\" select diagnosis.claim_id,diagnosis.patient_id,diagnosis.date_service,diagnosis.date_service_end,diagnosis_code,enrollment.patient_gender,patient_year_of_birth,sum(procedure.line_charge) as paid_amt \n",
    "from healthverity_claims_sample_patient_dataset.hv_claims_sample.diagnosis \n",
    "inner join healthverity_claims_sample_patient_dataset.hv_claims_sample.enrollment on diagnosis.patient_id = enrollment.patient_id\n",
    "inner join healthverity_claims_sample_patient_dataset.hv_claims_sample.procedure on diagnosis.patient_id = procedure.patient_id\n",
    "where admit_diagnosis_ind='Y'\n",
    "group by all\"\"\")\n",
    "raw = raw.withColumnRenamed(\"date_service\", \"admission_dt\").withColumnRenamed(\"date_service_end\", \"discharge_dt\").withColumnRenamed(\"diagnosis_code\",\"diag_cd\")\n",
    "raw.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15c9501-7ad3-466b-a5cb-c3551c7a212c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load BioBERT (pretrained)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b591de83-75d3-4b40-b19c-5f4c5b59bd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of diagnosis codes with the description\n",
    "code_desc = {\n",
    "    \"S066X0D\": \"Traumatic brain injury, unspecified, subsequent encounter\",\n",
    "    \"F1120\": \"Opioid dependence, uncomplicated\",\n",
    "    \"Z3483\": \"Encounter for supervision of high-risk pregnancy\",\n",
    "    \"K440\": \"Umbilical hernia without obstruction or gangrene\",\n",
    "    \"M75102\": \"Bursitis of right shoulder\",\n",
    "    \"I69354\": \"Hemiplegia and hemiparesis following cerebral infarction affecting left non-dominant side\",\n",
    "    \"L97929\": \"Non-pressure chronic ulcer of unspecified part of left lower leg with unspecified severity\",\n",
    "    \"R531\": \"Weakness\",\n",
    "    \"K5720\": \"Diverticulosis of intestine, part unspecified, without perforation or abscess\",\n",
    "    \"I214\": \"Acute subendocardial myocardial infarction\",\n",
    "    \"K9189\": \"Other postprocedural complications and disorders of digestive system\",\n",
    "    \"I495\": \"Sick sinus syndrome\",\n",
    "    \"S82122D\": \"Displaced transverse fracture of shaft of left tibia, subsequent encounter\",\n",
    "    \"T85730A\": \"Infection and inflammatory reaction due to other cardiac and vascular devices, implants and grafts, initial encounter\",\n",
    "    \"M238X2\": \"Other instability, left lower leg\",\n",
    "    \"R45851\": \"Suicidal ideation\",\n",
    "    \"G9341\": \"Acute encephalopathy\",\n",
    "    \"K8510\": \"Acute pancreatitis without necrosis or infection\",\n",
    "    \"R509\": \"Fever, unspecified\",\n",
    "    \"Z432\": \"Encounter for attention to gastrostomy\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9aedc22-2912-4f80-b353-c87c693126b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=64)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    print(emb.shape)\n",
    "    return emb\n",
    "\n",
    "# Precompute: Get embedding for every code\n",
    "dx_embeddings = {code: get_embedding(desc) for code, desc in code_desc.items()}\n",
    "\n",
    "embedding_size = list(dx_embeddings.values())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b070605-28cb-435a-acbd-4ce89456d671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 8)\nNumber of null length_of_stay values: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert diagnosis codes to vectors/embeddings\n",
    "def codes_to_vec(codes_str):\n",
    "    codes = codes_str.split('|')\n",
    "    vecs = [dx_embeddings[c] for c in codes if c in dx_embeddings]\n",
    "    if vecs:\n",
    "        return np.mean(vecs, axis=0)\n",
    "    else:  # Fallback: zero vector\n",
    "        return np.zeros(embedding_size)\n",
    "\n",
    "# Apply to your claims dataframe\n",
    "df =raw.toPandas()\n",
    "print(df.shape)\n",
    "df['admission_dt'] = pd.to_datetime(df['admission_dt'])\n",
    "df['discharge_dt'] = pd.to_datetime(df['discharge_dt']) \n",
    "\n",
    "# Feature engineering: calculate length of stay\n",
    "df['length_of_stay'] = (df['discharge_dt'] - df['admission_dt']).dt.days.astype('int') \n",
    "print(\"Number of null length_of_stay values:\", df['length_of_stay'].isnull().sum())\n",
    "\n",
    "df['dx_vec'] = df['diag_cd'].apply(codes_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "908bf8e1-0009-408e-80b4-533c29bff2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.          0.36756817 -0.1471743  ... -0.01323231  0.10032451\n  -0.3490597 ]\n [ 6.          0.03562754 -0.03531643 ...  0.25858146  0.05960665\n  -0.20098102]\n [11.         -0.06040566  0.14621527 ...  0.11308733  0.04431779\n  -0.09586126]\n ...\n [ 6.          0.03562754 -0.03531643 ...  0.25858146  0.05960665\n  -0.20098102]\n [ 6.          0.03562754 -0.03531643 ...  0.25858146  0.05960665\n  -0.20098102]\n [ 5.          0.11701713  0.20208992 ...  0.28921211  0.2184197\n  -0.08754165]]\n"
     ]
    }
   ],
   "source": [
    "# feature_matrix = np.vstack([\n",
    "#     np.concatenate([ [row.length_of_stay], row.dx_vec ])\n",
    "#     for idx, row in df.iterrows()\n",
    "# ])\n",
    "# print(feature_matrix)  # (num_claims, 2 + embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f913dd0f-a785-4897-8459-f575addf199a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First diagnosis:  R531\nSecond diagnosis:  R45851\nCosine similarity: 0.8664155\n"
     ]
    }
   ],
   "source": [
    "vec1 = df.iloc[0]['dx_vec']\n",
    "vec2 = df.iloc[30]['dx_vec']\n",
    "\n",
    "print(\"First diagnosis code: \",df.iloc[0]['diag_cd'])\n",
    "print(\"Second diagnosis code: \",df.iloc[30]['diag_cd'])\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "print('Cosine similarity:', cos_sim)\n",
    "# A cosine similarity value of 0.99 means that the two vectors (data points, text embeddings, or documents) are extremely similar and point in almost the exact same direction. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "biobert_embeddings_cosine_similarity",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
